{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e647a4",
   "metadata": {},
   "source": [
    "# Exercise Sheet 02: Principal Component Analysis, Factor Analysis, K-Means, and Gaussian Mixture Models\n",
    "\n",
    "**Introduction to Data Mining WS24/25**  \n",
    "**Bielefeld University**  \n",
    "**Alina Deriyeva, Adia Khalid, Benjamin Paa√üen**  \n",
    "**Exercise Sheet Publication Date: 2024-11-04**  \n",
    "**Exercise Sheet Submission Deadline: Friday, 2024-11-15, noon (i.e. 12:00), via moodle**\n",
    "\n",
    "**NOTE** The use of language models/AI tools is permitted under three conditions\n",
    "1. transparency: you tell us that you used them\n",
    "2. accountability: you take full responsibility for the submission, can explain and defend it\n",
    "3. privacy: you do not transmit any private information to any external tool\n",
    "\n",
    "We also appreciate it if you link to a chatlog of the interaction with the language model/AI tool for research purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8905f4",
   "metadata": {},
   "source": [
    "### Task 02.01\n",
    "\n",
    "Assume we have some encoding function $\\phi : R^n \\to R$ which maps input data points to single numbers in the latent space. Further, assume we want to find a linear decoding function $\\psi(z) = w \\cdot z$ which maps numbers in the latent space back to the input space such that the squared reconstruction error for an input data set $x_1, \\ldots, x_N \\in R^n$ is minimized.\n",
    "\n",
    "Formalize this problem as a minimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e2b5b",
   "metadata": {},
   "source": [
    "**ANSWER:** PLEASE PROVIDE LATEX CODE OR AN IMAGE OF YOUR DERIVATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71739d",
   "metadata": {},
   "source": [
    "### Task 02.02\n",
    "\n",
    "Recall the equation for the expected negative log likelihood in a Gaussian mixture model from the lecture:\n",
    "\n",
    "\\begin{align*}\n",
    "Q = &\\sum_{i=1}^N \\sum_{k=1}^K -\\gamma_{k,i} \\cdot \\log\\Big[ p_{X|Z}(x_i|k) \\cdot p_Z(k) \\Big]\\\\\n",
    "=& \\sum_{i=1}^N \\sum_{k=1}^K \\gamma_{k,i} \\cdot \\Big(\\frac{1}{2}\\log[2\\pi \\det(\\Sigma_k)] + \\frac{1}{2} (x_i - \\mu_k)^T \\Sigma_k^{-1} (x_i - \\mu_k) - \\log[p_Z(k)]\\Big)\n",
    "\\end{align*}\n",
    "\n",
    "Assuming that $Q$ is convex, find the optimal value for $\\mu_k$.\n",
    "\n",
    "**HINT:** You may use the following general matrix/vector gradient equation (refer to the [matrix cook book by Peterson and Pedersen (2012), p.10-11](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) :\n",
    "\\begin{align*}\n",
    "\\nabla_x (x - y)^T W (x - y) &= 2 W (x-y)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5403cd",
   "metadata": {},
   "source": [
    "**ANSWER:** PLEASE PROVIDE LATEX CODE OR AN IMAGE OF YOUR DERIVATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591c02c",
   "metadata": {},
   "source": [
    "## Preamble: Data set\n",
    "\n",
    "The file `sheet02_data.csv` contains fictional data as you might find in an online course. Each row represents a student, each column a feature of the student's activity in the course, namely their number of posts in the course discussion forum, the number of questions they asked in chat during the online lectures, the number of messages they sent to their peers, and the number of points they achieved in each of the five exercises of the course.\n",
    "\n",
    "Note that there is quite a bit of missing data for later exercises because many students dropped out of the course early.\n",
    "\n",
    "The following code loads this raw data and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d93f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  1.  1. ... 56. 61. 60.]\n",
      " [ 0.  0.  0. ... nan nan nan]\n",
      " [ 7.  3.  2. ... 66. 57. nan]\n",
      " ...\n",
      " [ 0.  0.  0. ... 30. nan nan]\n",
      " [ 1.  0.  0. ... nan nan nan]\n",
      " [ 3.  0.  1. ... 40. 35. 40.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['num_forum_postings',\n",
    "    'num_questions',\n",
    "    'num_messages',\n",
    "    'num_completed_tasks',\n",
    "    'points_exercise_1',\n",
    "    'points_exercise_2',\n",
    "    'points_exercise_3',\n",
    "    'points_exercise_4',\n",
    "    'points_exercise_5']\n",
    "\n",
    "X = np.loadtxt('sheet02_data.csv', skiprows = 1, delimiter = '\\t')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93d467",
   "metadata": {},
   "source": [
    "### Task 02.03\n",
    "\n",
    "Our first challenge is to impute the missing data. Fill in missing values with the mean points the respective student got on the other exercises. For students with no completed exercises, fill in zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3b0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0a0508",
   "metadata": {},
   "source": [
    "### Task 02.04\n",
    "\n",
    "Next, normalize the data by dividing by the maximum value in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6eba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "046940aa",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d3cbdb",
   "metadata": {},
   "source": [
    "### Task 02.05\n",
    "\n",
    "Compute the covariance matrix of the data via `np.cov` and compute the eigenvalues of the covariance matrix via `np.linalg.eigvals`. Provide a plot of the eigenvalues on the y-axis, sorted according to size (the largest eigenvalue at x=0, the second-largest on x=1, and so on).\n",
    "\n",
    "Compute and report the percentage of variance covered by the first two eigenvalues.\n",
    "\n",
    "**HINT:** `np.cov` treats the rows as variables and columns as observations. For our data set, rows are observations and columns are variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc8bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f98eecb2",
   "metadata": {},
   "source": [
    "### Task 02.06\n",
    "\n",
    "Use the `fit` method of a `sklearn.decomposition.PCA` model to perform a principal component analysis of this data with `n_components = 2`.\n",
    "\n",
    "Transform the data to the latent space via the `transform` function of the PCA model.\n",
    "\n",
    "Plot the data using a 2D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc00cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf401d8",
   "metadata": {},
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db42699",
   "metadata": {},
   "source": [
    "### Task 02.07\n",
    "\n",
    "Use the `fit` method of a `sklearn.decomposition.FactorAnalysis` model to perform a factor analysis of this data with `n_components = 2`. Use the `rotation = 'varimax'` parameter.\n",
    "\n",
    "Transform the data to the latent space via the `transform` function of the FA model.\n",
    "\n",
    "Plot the data using a 2D scatter plot.\n",
    "\n",
    "Compare this plot to the plot above. What difference do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12eb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d3915",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcdbed",
   "metadata": {},
   "source": [
    "### Task 02.08\n",
    "\n",
    "Print the factors found by the factor analysis using `print(model.components_)`. Try to interpret both factors. What does the first factor represent? What does the second factor represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21020ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d2763e9",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b286d18",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f384f8",
   "metadata": {},
   "source": [
    "### Task 02.09\n",
    "\n",
    "Using `sklearn.cluster.KMeans`, perform cluster analyses of the data for `n_clusters` between 2 and 10. For each value of `n_clusters`, compute the `sklearn.metrics.silhouette_score`. Provide a plot of the silhouette score on the y axis and `n_clusters` on the x axis. Report which value for `n_clusters` is best according to this analysis.\n",
    "\n",
    "**HINT:** The `silhouette_score` function requires the cluster labels as second argument. You can retrieve the cluster labels from a fitted `KMeans` model via the `predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e84c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63beff2e",
   "metadata": {},
   "source": [
    "### Task 02.10\n",
    "\n",
    "Using `sklearn.cluster.KMeans`, perform a cluster analysis of the data with `n_clusters = 2`.\n",
    "\n",
    "Get the cluster membership of each point via the `predict` function of the KMeans model.\n",
    "\n",
    "Provide a scatter plot of the latent representation of the data according to factor analysis, where the color of each point represents the cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e40a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96746798",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97836104",
   "metadata": {},
   "source": [
    "### Task 02.11\n",
    "\n",
    "Using `sklearn.mixture.GaussianMixture`, perform cluster analyses of the data with `n_components` between 2 and 10. For each cluster analysis, compute the `bic` function value of the model (this is the Bayesian information criterion). Provide a plot of the bic value on the y axis with `n_components` on the x axis.\n",
    "\n",
    "Report which value for `n_components` is best according to this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04aa8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df319c",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a6157",
   "metadata": {},
   "source": [
    "### Task 02.12\n",
    "\n",
    "Using `sklearn.mixture.GaussianMixture`, perform a cluster analysis of the data with `n_components = 2`.\n",
    "\n",
    "Get the cluster membership of each point via the `predict` function of the GaussianMixture model.\n",
    "\n",
    "Provide a scatter plot of the latent representation of the data according to factor analysis, where the color of each point represents the cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40f016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3d36096",
   "metadata": {},
   "source": [
    "### Task 02.13\n",
    "\n",
    "Using `sklearn.mixture.GaussianMixture`, perform a cluster analysis of the latent space representation according to factor analysis with `n_components = 3`.\n",
    "\n",
    "Get the cluster membership of each point via the `predict` function of the GaussianMixture model.\n",
    "\n",
    "Provide a scatter plot, where the color of each point represents the cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52229929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce20f6b2",
   "metadata": {},
   "source": [
    "### Task 02.14\n",
    "\n",
    "Print the mean feature values for each cluster. Try to interpret the clusters: What characterizes the differenct clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16bd57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa3ae774",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
