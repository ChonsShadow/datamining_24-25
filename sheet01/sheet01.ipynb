{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 01: Data preprocessing, visualization, correlation, statistical testing, and modeling\n",
    "\n",
    "**Introduction to Data Mining WS24/25**  \n",
    "**Bielefeld University**  \n",
    "**Alina Deriyeva, Adia Khalid, Benjamin PaaÃŸen**  \n",
    "**Exercise Sheet Publication Date: 2024-10-23**  \n",
    "**Exercise Sheet Submission Deadline: Friday, 2024-11-01, noon (i.e. 12:00), via moodle**\n",
    "\n",
    "**NOTE** The use of language models/AI tools is permitted under three conditions\n",
    "1. transparency: you tell us that you used them\n",
    "2. accountability: you take full responsibility for the submission, can explain and defend it\n",
    "3. privacy: you do not transmit any private information to any external tool\n",
    "\n",
    "We also appreciate it if you link to a chatlog of the interaction with the language model/AI tool for research purposes."
   ],
   "id": "a2278fda2cb88afd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Modeling\n",
    "\n",
    "Let's assume that a student does a test on a single topic in which they can achieve a certain number of points. Let's further assume that the probability that the student has understood the topic is denoted as $p \\in [0, 1]$. Finally, let's assume that the number of points on the test Gaussian distributed with standard deviation $\\sigma > 0$. However, the mean of the distribution depends on whether the student has understood the topic or not."
   ],
   "id": "992e878f84c6b90f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.01\n",
    "\n",
    "Formalize this scenario. In particular:\n",
    "1. Model a random variable $Z$ that indicates whether the student understood the topic or not. What is the domain? What is the probability mass function $p_Z$? What are the parameters of this function?\n",
    "2. Model a random variable $X$ for the number of points the student achieves on the test. What is the conditional probability density function $p_{X|Z}$? What are the parameters of this function?\n",
    "\n",
    "#### Sub-task 1\n",
    "$Z = (\\mathcal{Z}, p_Z)$\\\n",
    "With $\\mathcal{Z} = \\{0,1\\}$ (domain) and $p_Z: \\mathcal{Z} -> \\mathbb{R}$ (probability mass function)\\\n",
    "For notation, we will just write the parameters of the probability mass function implicitly: \\\n",
    "$p_Z(Z=0) = 1-p\\quad$ and $\\quad p_Z(Z=1) = p$\\\n",
    "\n",
    "<br/><br/>\n",
    "#### Sub-task 2\n",
    "\n",
    "$X = (\\mathcal{X}, p_X)$\\\n",
    "With $\\mathcal{X} = \\{0, ..., N\\}$, with $N$ being the maximum number of points in the test.\\\n",
    "Since the number of points a student achieves is Gaussian distributed with $\\mu$ and $\\sigma > 0$, we can write $p_X$ as \\\n",
    "$p_X(x) = \\dfrac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left( -\\frac{(x - \\mu)^2}{2 \\sigma^2} \\right)$\\\n",
    "\\\n",
    "We are now interested in the conditional probability density function of X in relation to Z. This just follows from Bayes' Theorem:\\\n",
    "$p_{X|Z}(x\\,|\\,z) = \\dfrac{p_{Z|X}(z\\,|\\,x) \\, p_X(x)}{p_Z(z)}$\\\n",
    "In this case, the parameter $x$ stands for the points achieved, and $z$ wheter or not the student has understood the topic.\n",
    "Once again, we can use the slightly different notation used in Z to make it a bit clearer:\\\n",
    "$p_{X|Z}(X=x\\,|\\,Z=z) = \\dfrac{p_{Z|X}(Z=z\\,|\\,X=x) \\, p_X(X=x)}{p_Z(Z=z)}$\\\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "76c23b3fdfe034f8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.02\n",
    "\n",
    "Using Bayes' theorem and the law of total probability, compute the conditional probability mass $p_{Z|X}(1|x)$ for the student having understood the topic given their achieved number of points.\n",
    "\n",
    "$p_{Z|X}(Z=1\\,|\\,X=x) = \\dfrac{p_{X|Z}(X=x\\,|\\,Z=1) \\, p_Z(Z=1)}{p_X(X=x)} = \\dfrac{p_{X|Z}(X=x\\,|\\,Z=1) \\, p}{p_X(X=x)} = \\dfrac{p_{X|Z}(X=x\\,|\\,Z=1) \\, p}{p_{X|Z}(X=x\\,|\\,Z=0) \\cdot p_Z(Z=0) + p_{X|Z}(X=x\\,|\\,Z=1) \\cdot p_Z(Z=1)}$\\\n",
    "$= \\dfrac{p_{X|Z}(X=x\\,|\\,Z=1) \\, p}{p_{X|Z}(X=x\\,|\\,Z=0) \\cdot (1-p) + p_{X|Z}(X=x\\,|\\,Z=1) \\cdot p}$\n",
    "$= \\dfrac{1}{\\frac{p_{X|Z}(X=x\\,|\\,Z=0)}{p_{X|Z}(X=x\\,|\\,Z=1)} \\cdot \\frac{(1-p)}{p} + 1}$\n",
    "\n",
    "<!-- We can continue to reduce this in size by assuming tgat  p_{X|Z}(X=x\\,|\\,Z=1) and p_{X|Z}(X=x\\,|\\,Z=0) only differentiate by a shifted mean.-->"
   ],
   "id": "1a330549866ff261"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.03\n",
    "\n",
    "Assume that the numbers $x_1, \\ldots, x_m \\in \\mathbb{R}$ are generated (independently) from a Gaussian with mean $\\mu$ and standard deviation $\\sigma$.\n",
    "\n",
    "1. What is the negative log likelihood of the data under this assumption?\n",
    "2. Prove that $\\mu$ and $\\sigma^2$ which minimize the negative log likelihood are exactly $\\mu = \\frac{1}{m} \\sum_{i=1}^m x_i$ and $\\sigma^2 = \\frac{1}{m} \\sum_{i=1}^m (x_i - \\mu)^2$. You may assume that the negative log likelihood is convex, in this case."
   ],
   "id": "40cb70ec0d785676"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER** PLEASE PROVIDE LATEX CODE OR AN IMAGE OF YOUR DERIVATION HERE"
   ],
   "id": "1ccc33e450c8918b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data set\n",
    "\n",
    "In this exercise sheet, we investigate first data exploration activities that can be performed on typical, tabular data sets, up to simple statistical testing.\n",
    "\n",
    "The file `sheet01_data.csv` contains fictional data as might be produced in an educational study. Each row represents a student participating in the study. The first column is just the student index, the second column indicates the experimental condition the student was in (`0` for control group, `1` for intervention group). The third column is the student's test result on a pre-test, the fourth column is the student's test result on a post-test.\n",
    "\n",
    "The following line loads this raw data and prints it."
   ],
   "id": "d2731d22af8aceb9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:32:10.071422Z",
     "start_time": "2024-10-26T14:32:10.065208Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "X = np.loadtxt('sheet01_data.csv', skiprows = 1, delimiter = '\\t')\n",
    "print(X)"
   ],
   "id": "a286af134d20cc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.  27.  40.]\n",
      " [  1.   0.  31.  34.]\n",
      " [  2.   0.  30.  nan]\n",
      " [  3.   0.  20.  nan]\n",
      " [  4.   0.  41.  54.]\n",
      " [  5.   0.  39.  51.]\n",
      " [  6.   0.  20.  33.]\n",
      " [  7.   0.  27.  36.]\n",
      " [  8.   0.  79.  83.]\n",
      " [  9.   0.  33.  46.]\n",
      " [ 10.   0.  22.  29.]\n",
      " [ 11.   0.  22.  41.]\n",
      " [ 12.   0.  29.  nan]\n",
      " [ 13.   0.  25.  nan]\n",
      " [ 14.   0.  41.  47.]\n",
      " [ 15.   0.  23.  36.]\n",
      " [ 16.   0.  17.  30.]\n",
      " [ 17.   0.  93. 100.]\n",
      " [ 18.   0.  34.  40.]\n",
      " [ 19.   0.  23.  27.]\n",
      " [ 20.   0.  48.  53.]\n",
      " [ 21.   0.  19.  26.]\n",
      " [ 22.   0.  28.  33.]\n",
      " [ 23.   0.  38.  46.]\n",
      " [ 24.   0.  22.  34.]\n",
      " [ 25.   0.  34.  45.]\n",
      " [ 26.   0.  36.  49.]\n",
      " [ 27.   0.  33.  47.]\n",
      " [ 28.   0.  40.  41.]\n",
      " [ 29.   0.  39.  52.]\n",
      " [ 30.   1.  24.  50.]\n",
      " [ 31.   1.  38.  62.]\n",
      " [ 32.   1.  34.  51.]\n",
      " [ 33.   1.  37.  nan]\n",
      " [ 34.   1.  31.  44.]\n",
      " [ 35.   1.  37.  57.]\n",
      " [ 36.   1.  25.  50.]\n",
      " [ 37.   1.  23.  37.]\n",
      " [ 38.   1.  12.  38.]\n",
      " [ 39.   1.  31.  56.]\n",
      " [ 40.   1.  36.  46.]\n",
      " [ 41.   1.  34.  48.]\n",
      " [ 42.   1.  85. 100.]\n",
      " [ 43.   1.  41.  59.]\n",
      " [ 44.   1.  14.  37.]\n",
      " [ 45.   1.   7.  29.]\n",
      " [ 46.   1.  30.  54.]\n",
      " [ 47.   1.  42.  62.]\n",
      " [ 48.   1.  25.  44.]\n",
      " [ 49.   1.  29.  53.]\n",
      " [ 50.   1.  17.  40.]\n",
      " [ 51.   1.  40.  63.]\n",
      " [ 52.   1.  29.  46.]\n",
      " [ 53.   1.  33.  nan]\n",
      " [ 54.   1.  24.  50.]\n",
      " [ 55.   1.  38.  53.]\n",
      " [ 56.   1.  26.  48.]\n",
      " [ 57.   1.  41.  nan]\n",
      " [ 58.   1.  37.  65.]\n",
      " [ 59.   1.  41.  61.]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.04\n",
    "\n",
    "Write python code to automatically identify outliers, which are defined as any students with a pre-test score higher than 3 standard deviations above the mean. Write python code that removes these outliers from the data set."
   ],
   "id": "99b8b869442d1724"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:55:00.749041Z",
     "start_time": "2024-10-26T14:55:00.743455Z"
    }
   },
   "source": [
    "pre_scores = np.array(X[:, 2])\n",
    "\n",
    "mean_pre_score = np.mean(pre_scores)\n",
    "std_pre_score = np.std(pre_scores)\n",
    "\n",
    "k_filter = mean_pre_score + 3 * std_pre_score\n",
    "cleaned_X = X[X[:, 2] <= k_filter]\n",
    "print(cleaned_X)"
   ],
   "id": "fec8433bab1934c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0. 27. 40.]\n",
      " [ 1.  0. 31. 34.]\n",
      " [ 2.  0. 30. nan]\n",
      " [ 3.  0. 20. nan]\n",
      " [ 4.  0. 41. 54.]\n",
      " [ 5.  0. 39. 51.]\n",
      " [ 6.  0. 20. 33.]\n",
      " [ 7.  0. 27. 36.]\n",
      " [ 9.  0. 33. 46.]\n",
      " [10.  0. 22. 29.]\n",
      " [11.  0. 22. 41.]\n",
      " [12.  0. 29. nan]\n",
      " [13.  0. 25. nan]\n",
      " [14.  0. 41. 47.]\n",
      " [15.  0. 23. 36.]\n",
      " [16.  0. 17. 30.]\n",
      " [18.  0. 34. 40.]\n",
      " [19.  0. 23. 27.]\n",
      " [20.  0. 48. 53.]\n",
      " [21.  0. 19. 26.]\n",
      " [22.  0. 28. 33.]\n",
      " [23.  0. 38. 46.]\n",
      " [24.  0. 22. 34.]\n",
      " [25.  0. 34. 45.]\n",
      " [26.  0. 36. 49.]\n",
      " [27.  0. 33. 47.]\n",
      " [28.  0. 40. 41.]\n",
      " [29.  0. 39. 52.]\n",
      " [30.  1. 24. 50.]\n",
      " [31.  1. 38. 62.]\n",
      " [32.  1. 34. 51.]\n",
      " [33.  1. 37. nan]\n",
      " [34.  1. 31. 44.]\n",
      " [35.  1. 37. 57.]\n",
      " [36.  1. 25. 50.]\n",
      " [37.  1. 23. 37.]\n",
      " [38.  1. 12. 38.]\n",
      " [39.  1. 31. 56.]\n",
      " [40.  1. 36. 46.]\n",
      " [41.  1. 34. 48.]\n",
      " [43.  1. 41. 59.]\n",
      " [44.  1. 14. 37.]\n",
      " [45.  1.  7. 29.]\n",
      " [46.  1. 30. 54.]\n",
      " [47.  1. 42. 62.]\n",
      " [48.  1. 25. 44.]\n",
      " [49.  1. 29. 53.]\n",
      " [50.  1. 17. 40.]\n",
      " [51.  1. 40. 63.]\n",
      " [52.  1. 29. 46.]\n",
      " [53.  1. 33. nan]\n",
      " [54.  1. 24. 50.]\n",
      " [55.  1. 38. 53.]\n",
      " [56.  1. 26. 48.]\n",
      " [57.  1. 41. nan]\n",
      " [58.  1. 37. 65.]\n",
      " [59.  1. 41. 61.]]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print how many points are left in the control group and the intervention group after outlier removal"
   ],
   "id": "8a1d2244ca0584be"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:54:10.511976Z",
     "start_time": "2024-10-26T14:54:10.509239Z"
    }
   },
   "source": [
    "cleaned_control = len(cleaned_X[cleaned_X[:, 1] == 0])\n",
    "cleaned_interv = len(cleaned_X[cleaned_X[:, 1] == 1])\n",
    "      \n",
    "print(\"Group sizes after outlier removal\")  \n",
    "print(\"control:\", cleaned_control, \"\\nintervention:\", cleaned_interv)"
   ],
   "id": "54817ba5e9acda13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group sizes after outlier removal\n",
      "control: 28 \n",
      "intervention: 29\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.05\n",
    "\n",
    "Write python code to compute the mean pre- and post-test score, as well as the respective standard deviation, of the control group and the intervention group. Be aware of nan values. Print the results."
   ],
   "id": "c4cc60afdd8de021"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:02:30.444248Z",
     "start_time": "2024-10-26T15:02:30.435020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "control_group = cleaned_X[cleaned_X[:, 1] == 0]\n",
    "intervention_group = cleaned_X[cleaned_X[:, 1] == 1]\n",
    "\n",
    "# use nps nan functions for calculating metrics to ignore nan values\n",
    "\n",
    "control_pre_mean = np.nanmean(control_group[:, 2])\n",
    "control_pre_std = np.nanstd(control_group[:, 2])\n",
    "control_post_mean = np.nanmean(control_group[:, 3])\n",
    "control_post_std = np.nanstd(control_group[:, 3])\n",
    "\n",
    "intervention_pre_mean = np.nanmean(intervention_group[:, 2])\n",
    "intervention_pre_std = np.nanstd(intervention_group[:, 2])\n",
    "intervention_post_mean = np.nanmean(intervention_group[:, 3])\n",
    "intervention_post_std = np.nanstd(intervention_group[:, 3])\n",
    "\n",
    "print(\"control group, pre-tests: \")\n",
    "print(\"mean: \", control_pre_mean, \"std: \", control_pre_std)\n",
    "print(\"control group, post-tests: \")\n",
    "print(\"mean: \", control_post_mean, \"std: \", control_post_std)\n",
    "print(\"_\"*50)\n",
    "print(\"intervention group, pre-tests: \")\n",
    "print(\"mean: \", intervention_pre_mean, \"std: \", intervention_pre_std)\n",
    "print(\"intervention group, post-tests: \")\n",
    "print(\"mean: \", intervention_post_mean, \"std: \", intervention_post_std)"
   ],
   "id": "f89717f305a6b45a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control group, pre-tests: \n",
      "mean:  30.035714285714285 std:  8.033332980495095\n",
      "control group, post-tests: \n",
      "mean:  40.416666666666664 std:  8.396014266040497\n",
      "__________________________________________________\n",
      "intervention group, pre-tests: \n",
      "mean:  30.20689655172414 std:  9.147750092122058\n",
      "intervention group, post-tests: \n",
      "mean:  50.11538461538461 std:  9.069504791319277\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.06\n",
    "\n",
    "Write python code to impute the missing values (that means: nan values) in the post test scores by the mean of the data. HOWEVER, the imputation should be done separately for the control and the intervention group."
   ],
   "id": "c364a97feca28969"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:02:41.745102Z",
     "start_time": "2024-10-26T15:02:41.740642Z"
    }
   },
   "source": [
    "import math\n",
    "for i, x in enumerate(cleaned_X):\n",
    "    if not math.isnan(x[3]):\n",
    "        continue\n",
    "        \n",
    "    if x[1]:\n",
    "        cleaned_X[i][3] = intervention_post_mean\n",
    "        continue\n",
    "        \n",
    "    cleaned_X[i][3] = control_post_mean\n",
    "            \n",
    "print(cleaned_X)"
   ],
   "id": "8dc780f25ed20ff4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.         27.         40.        ]\n",
      " [ 1.          0.         31.         34.        ]\n",
      " [ 2.          0.         30.         40.41666667]\n",
      " [ 3.          0.         20.         40.41666667]\n",
      " [ 4.          0.         41.         54.        ]\n",
      " [ 5.          0.         39.         51.        ]\n",
      " [ 6.          0.         20.         33.        ]\n",
      " [ 7.          0.         27.         36.        ]\n",
      " [ 9.          0.         33.         46.        ]\n",
      " [10.          0.         22.         29.        ]\n",
      " [11.          0.         22.         41.        ]\n",
      " [12.          0.         29.         40.41666667]\n",
      " [13.          0.         25.         40.41666667]\n",
      " [14.          0.         41.         47.        ]\n",
      " [15.          0.         23.         36.        ]\n",
      " [16.          0.         17.         30.        ]\n",
      " [18.          0.         34.         40.        ]\n",
      " [19.          0.         23.         27.        ]\n",
      " [20.          0.         48.         53.        ]\n",
      " [21.          0.         19.         26.        ]\n",
      " [22.          0.         28.         33.        ]\n",
      " [23.          0.         38.         46.        ]\n",
      " [24.          0.         22.         34.        ]\n",
      " [25.          0.         34.         45.        ]\n",
      " [26.          0.         36.         49.        ]\n",
      " [27.          0.         33.         47.        ]\n",
      " [28.          0.         40.         41.        ]\n",
      " [29.          0.         39.         52.        ]\n",
      " [30.          1.         24.         50.        ]\n",
      " [31.          1.         38.         62.        ]\n",
      " [32.          1.         34.         51.        ]\n",
      " [33.          1.         37.         50.11538462]\n",
      " [34.          1.         31.         44.        ]\n",
      " [35.          1.         37.         57.        ]\n",
      " [36.          1.         25.         50.        ]\n",
      " [37.          1.         23.         37.        ]\n",
      " [38.          1.         12.         38.        ]\n",
      " [39.          1.         31.         56.        ]\n",
      " [40.          1.         36.         46.        ]\n",
      " [41.          1.         34.         48.        ]\n",
      " [43.          1.         41.         59.        ]\n",
      " [44.          1.         14.         37.        ]\n",
      " [45.          1.          7.         29.        ]\n",
      " [46.          1.         30.         54.        ]\n",
      " [47.          1.         42.         62.        ]\n",
      " [48.          1.         25.         44.        ]\n",
      " [49.          1.         29.         53.        ]\n",
      " [50.          1.         17.         40.        ]\n",
      " [51.          1.         40.         63.        ]\n",
      " [52.          1.         29.         46.        ]\n",
      " [53.          1.         33.         50.11538462]\n",
      " [54.          1.         24.         50.        ]\n",
      " [55.          1.         38.         53.        ]\n",
      " [56.          1.         26.         48.        ]\n",
      " [57.          1.         41.         50.11538462]\n",
      " [58.          1.         37.         65.        ]\n",
      " [59.          1.         41.         61.        ]]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ],
   "id": "8648b389d8efbecc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.07\n",
    "\n",
    "Display two scatter plots (via `matplotlib.pyplot.scatter`), one for the control group and one for the intervention group, with pre-test score on the x-axis and post-test score on the y-axis. Label the axis and give the plots titles. Interpret these plot: Do you believe that pre- and post-test score correlate?"
   ],
   "id": "a75f0f9673d0aac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:16:59.429459Z",
     "start_time": "2024-10-26T15:16:59.328576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(control_group[:, 2], control_group[:, 3], label=\"Control\")\n",
    "ax1.scatter(intervention_group[:, 2], intervention_group[:, 3], label=\"Intervention\")\n",
    "plt.legend(loc='upper left')\n",
    "ax1.set_xlabel('pre-test scores')\n",
    "ax1.set_ylabel('post-test scores')\n",
    "ax1.set_title('Test Scores')\n",
    "ax1.set_xlim([0, 55])\n",
    "ax1.set_ylim([10, 70])\n",
    "plt.show()"
   ],
   "id": "97ed1b74c4a22a49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "Yes, pre- and post-test scores do seem to correlate highly. We can easily see (and potentially draw!) a linear function describing the correlation between them.\n",
    "\n",
    "This makes intuitive sense, as somebody who scored higher in the pre-test is more likely to repeat a higher score in the post-test."
   ],
   "id": "ecb065e9694b9e0f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.08\n",
    "\n",
    "Display a bar plot with four bars (with error bars): pre-test mean (with standard error) for control and intervention group; and post-test mean (with standard error) for control and intervention group. Label the axes. Interpret this plot: Where are significant differences, do you think? What is your explanation for these differences?"
   ],
   "id": "79e43a3326bd9822"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "98a03b0303e8d92f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n"
   ],
   "id": "cbfb93a02ce45dae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.09\n",
    "\n",
    "Display a bar plot with two bars (with error bars): the average difference between post- and pre-test score for the control group (with standard error) and for the intervention group (with standard error). Label the axes. Interpret this plot: Do you think the difference of post- and pre-test scores significantly differs between control and intervention group?"
   ],
   "id": "7733b34dc0efdd75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "682fa14e62019702"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ],
   "id": "c4729c1596c03047"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Testing"
   ],
   "id": "c75aad4fcb80b383"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.10\n",
    "\n",
    "Write a python function to compute the Pearson correlation between two arrays of the same size."
   ],
   "id": "bc2b3ac43828fb58"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonr(x, y):\n",
    "    # TODO IMPLEMENT THIS FUNCTION\n",
    "    return None "
   ],
   "id": "42c01e1a2fd67749"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.11\n",
    "\n",
    "Use your function to compute the Pearson correlation between pre-test and post-test scores for both control and intervention condition and print the scores.\n",
    "\n",
    "Interpret the strength of the correlation using the following rule of thumb from [Mukaka (2012)](https://www.ajol.info/index.php/mmj/article/download/81576/71739):\n",
    "\n",
    "* A correlation of $0.3 < |r| \\leq 0.5$ is considered small.\n",
    "* A correlation of $0.5 < |r| \\leq 0.7$ is considered moderate.\n",
    "* A correlation of $0.7 < |r| \\leq 0.9$ is considered high.\n",
    "* A correlation of $0.9 < |r| \\leq 1.0$ is considered very high."
   ],
   "id": "ce8c8590712a3f82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "d101d24c53299cbd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate your scores by computing the Pearson correlation again with `scipy.stats.pearsonr`. Print both `r` and the `p` value returned by the function for both the control and the intervention condition. Are the correlations statistically significant at $0.01$ level?"
   ],
   "id": "db4c28cbecb458f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "3b5a473f0782a5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.12\n",
    "\n",
    "Write a python function that performs a Welch $t$-test. In particular, your function should:\n",
    "1. compute the number of data points, the mean, and the standard deviation of both samples (use the `ddof = 1` parameter for the `np.std` function).\n",
    "2. compute the pooled standard deviation as\n",
    "\\begin{equation}\n",
    "\\sigma_\\text{pooled} = \\sqrt{\\frac{\\sigma_x^2}{n_x} + \\frac{\\sigma_y^2}{n_y}}\n",
    "\\end{equation}\n",
    "  where $n_x$ and $n_y$ are the number of data points in the two samples and $\\sigma_x$ and $\\sigma_y$ are the respective standard deviations.\n",
    "3. compute the $t$-statistic as \n",
    "\\begin{equation}\n",
    "t = -\\Big|\\frac{\\mu_x - \\mu_y}{\\sigma_\\text{pooled}}\\Big|\n",
    "\\end{equation}\n",
    "  where $\\mu_x$ and $\\mu_y$ are the means of the two samples.\n",
    "4. compute the number of degree of freedom via the Welch-Satterthwaite equation, meaning:\n",
    "\\begin{equation}\n",
    "\\text{df} = \\frac{\\sigma_\\text{pooled}^4}{\\frac{\\sigma_x^4}{n_x^2\\cdot(n_x - 1)} + \\frac{\\sigma_y^4}{n_y^2\\cdot(n_y - 1)}}\n",
    "\\end{equation}\n",
    "5. compute $p$ as twice the probability of any $t$ value equal or smaller to your value using the `cdf` function of `scipy.stats.t` with the number of freedoms as computed in the previous step.\n",
    "\n",
    "Your function should return both $t$ and $p$."
   ],
   "id": "3c3b6b4b58bfc928"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(x, y):\n",
    "    # number of data points\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    # means\n",
    "    mx = np.mean(x)\n",
    "    my = np.mean(y)\n",
    "    # standard deviations\n",
    "    sx = np.std(x, ddof = 1)\n",
    "    sy = np.std(y, ddof = 1)\n",
    "\n",
    "    # pooled standard deviation\n",
    "    sp = None # TODO IMPLEMENT THIS\n",
    "\n",
    "    # degrees of freedom\n",
    "    df = None # TODO IMPLEMENT THIS\n",
    "    \n",
    "    # t-statistic\n",
    "    t = None # TODO IMPLEMENT THIS\n",
    "\n",
    "    # cumulative probability\n",
    "    p  = 2*scipy.stats.t.cdf(t, df = df)\n",
    "    \n",
    "    return t, p"
   ],
   "id": "da720bb7d7ca4c55"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.13\n",
    "\n",
    "Write python code to perform the following Welch tests (using your function):\n",
    "1. the pre-test scores in the control versus the intervention condition\n",
    "2. the post-test scores in the control versus the intervention condition\n",
    "3. the differences between post- and pre-test scores in the control versus the intervention condition\n",
    "\n",
    "For each of the tests, print the $t$ and $p$.\n",
    "\n",
    "Which of the test results are significant at a $0.01$-level?\n",
    "\n",
    "**Hint:** You can validate that your function returns the correct $t$ and $p$ values by comparing to the output of the function `scipy.stats.ttest_ind` with `equal_var = False`."
   ],
   "id": "d62f7cf13d8bf8c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "d79f921815ff5db6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01.14\n",
    "\n",
    "Compute the effect sizes for the difference in post-test minus pre-test score between control and intervention condition using the formula\n",
    "\n",
    "\\begin{equation}\n",
    "d = \\frac{|\\mu_x - \\mu_y|}{\\sqrt{\\frac{1}{2}(\\sigma_x^2 + \\sigma_y^2)}}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mu_x$ and $\\mu_y$ are the mean score difference in intervention and control condition and $\\sigma_x$ and $\\sigma_y$ are the respective standard deviations.\n",
    "\n",
    "Print the effect size and interpret the size of the effect using the following rule of thumb (by [Sawilowsky (2009)](https://digitalcommons.wayne.edu/cgi/viewcontent.cgi?article=1536&context=jmasm))\n",
    "* An effect of size $0.01 < d \\leq 0.2$ is considered very small.\n",
    "* An effect of size $0.2 < d \\leq 0.5$ is considered small.\n",
    "* An effect of size $0.5 < d \\leq 0.8$ is considered moderate.\n",
    "* An effect of size $0.8 < d \\leq 1.2$ is considered large.\n",
    "* An effect of size $1.2 < d \\leq 2.0$ is considered very large.\n",
    "* An effect of size $d > 2.0$ is considered huge."
   ],
   "id": "2e87e84061e296d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "e5482122818e713b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
